{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1. Linear, Ridge, and Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imported the packages: csv, Pandas, Scikit-learn, Numpy, Networkx, collections.\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy.linalg as linalg\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import sklearn\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import cluster\n",
    "import networkx as nx\n",
    "from collections import defaultdict\n",
    "\n",
    "# Imported the train data.\n",
    "with open(\"/Users/advaitiyer/Desktop/Syracuse University/Academics/3rd Semester/Analytical Data Mining CIS 787/Homeworks/HW4/blogData_train.csv\") as csvfile:\n",
    "    file1=csv.reader(csvfile,delimiter=',')\n",
    "    train_list=[]\n",
    "    for row in file1:\n",
    "        train_list.append(row)\n",
    "# Split the train data into x_train (predictors) and y_train (target).\n",
    "x_train1=pd.DataFrame(train_list)\n",
    "x_train=x_train1.loc[:,:279]\n",
    "\n",
    "y_train=x_train1[280]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imported the test data.\n",
    "with open(\"/Users/advaitiyer/Desktop/Syracuse University/Academics/3rd Semester/Analytical Data Mining CIS 787/Homeworks/HW4/blogData_test-2012.03.31.01_00.csv\") as csvfile1:\n",
    "    file2=csv.reader(csvfile1,delimiter=',')\n",
    "    test_list=[]\n",
    "    for row in file2:\n",
    "        test_list.append(row)\n",
    "# Split the test data into x_test (predictors), and y_test (target).\n",
    "x_test1=pd.DataFrame(test_list)\n",
    "x_test=x_test1.loc[:,:279]\n",
    "\n",
    "y_test=x_test1[280]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 1: Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train error: 30.053 test error: 40.399\n"
     ]
    }
   ],
   "source": [
    "# Fit the model.\n",
    "lr=linear_model.LinearRegression(fit_intercept=True)\n",
    "lr.fit(x_train,y_train)\n",
    "# Calculate errors in train and test sets.\n",
    "new_train_error = np.sqrt(mean_squared_error(y_train, lr.predict(x_train)))\n",
    "new_test_error = np.sqrt(mean_squared_error(y_test, lr.predict(x_test)))\n",
    "# Print the errors as report.\n",
    "print('train RMSE: {} test RMSE: {}'.format(round(new_train_error,3),round(new_test_error,3)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 2: Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha: 0.0 | train error: 30.052684 test error: 40.39306\n",
      "alpha: 0.2 | train error: 30.054198 test error: 40.394887\n",
      "alpha: 0.4 | train error: 30.054237 test error: 40.396618\n",
      "alpha: 0.6000000000000001 | train error: 30.054291 test error: 40.398181\n",
      "alpha: 0.8 | train error: 30.054356 test error: 40.399609\n",
      "alpha: 1.0 | train error: 30.054429 test error: 40.400926\n",
      "alpha: 1.2000000000000002 | train error: 30.054507 test error: 40.402151\n",
      "alpha: 1.4000000000000001 | train error: 30.054589 test error: 40.403296\n",
      "alpha: 1.6 | train error: 30.054674 test error: 40.404375\n",
      "alpha: 1.8 | train error: 30.054761 test error: 40.405395\n",
      "alpha: 2.0 | train error: 30.05485 test error: 40.406363\n",
      "alpha: 2.2 | train error: 30.054941 test error: 40.407286\n",
      "alpha: 2.4000000000000004 | train error: 30.055032 test error: 40.408169\n",
      "alpha: 2.6 | train error: 30.055124 test error: 40.409015\n",
      "alpha: 2.8000000000000003 | train error: 30.055216 test error: 40.409829\n",
      "alpha: 3.0 | train error: 30.055308 test error: 40.410613\n",
      "alpha: 3.2 | train error: 30.055401 test error: 40.41137\n",
      "alpha: 3.4000000000000004 | train error: 30.055493 test error: 40.412103\n",
      "alpha: 3.6 | train error: 30.055586 test error: 40.412813\n",
      "alpha: 3.8000000000000003 | train error: 30.055678 test error: 40.413502\n",
      "alpha: 4.0 | train error: 30.05577 test error: 40.414171\n",
      "alpha: 4.2 | train error: 30.055862 test error: 40.414823\n",
      "alpha: 4.4 | train error: 30.055953 test error: 40.415458\n",
      "alpha: 4.6000000000000005 | train error: 30.056044 test error: 40.416078\n",
      "alpha: 4.800000000000001 | train error: 30.056134 test error: 40.416683\n",
      "alpha: 5.0 | train error: 30.056224 test error: 40.417274\n",
      "alpha: 5.2 | train error: 30.056314 test error: 40.417852\n",
      "alpha: 5.4 | train error: 30.056403 test error: 40.418419\n",
      "alpha: 5.6000000000000005 | train error: 30.056492 test error: 40.418974\n",
      "alpha: 5.800000000000001 | train error: 30.05658 test error: 40.419518\n",
      "alpha: 6.0 | train error: 30.056668 test error: 40.420051\n",
      "alpha: 6.2 | train error: 30.056755 test error: 40.420576\n",
      "alpha: 6.4 | train error: 30.056841 test error: 40.42109\n",
      "alpha: 6.6000000000000005 | train error: 30.056928 test error: 40.421596\n",
      "alpha: 6.800000000000001 | train error: 30.057013 test error: 40.422094\n",
      "alpha: 7.0 | train error: 30.057098 test error: 40.422584\n",
      "alpha: 7.2 | train error: 30.057183 test error: 40.423066\n",
      "alpha: 7.4 | train error: 30.057267 test error: 40.42354\n",
      "alpha: 7.6000000000000005 | train error: 30.057351 test error: 40.424008\n",
      "alpha: 7.800000000000001 | train error: 30.057434 test error: 40.424468\n",
      "alpha: 8.0 | train error: 30.057516 test error: 40.424923\n",
      "alpha: 8.200000000000001 | train error: 30.057598 test error: 40.425371\n",
      "alpha: 8.4 | train error: 30.057679 test error: 40.425813\n",
      "alpha: 8.6 | train error: 30.05776 test error: 40.426249\n",
      "alpha: 8.8 | train error: 30.057841 test error: 40.426679\n",
      "alpha: 9.0 | train error: 30.057921 test error: 40.427104\n",
      "alpha: 9.200000000000001 | train error: 30.058 test error: 40.427524\n",
      "alpha: 9.4 | train error: 30.058079 test error: 40.427939\n",
      "alpha: 9.600000000000001 | train error: 30.058158 test error: 40.428349\n",
      "alpha: 9.8 | train error: 30.058236 test error: 40.428755\n",
      "alpha: 10.0 | train error: 30.058313 test error: 40.429156\n",
      "alpha: 10.200000000000001 | train error: 30.05839 test error: 40.429552\n",
      "alpha: 10.4 | train error: 30.058467 test error: 40.429944\n",
      "alpha: 10.600000000000001 | train error: 30.058543 test error: 40.430332\n",
      "alpha: 10.8 | train error: 30.058618 test error: 40.430715\n",
      "alpha: 11.0 | train error: 30.058693 test error: 40.431095\n",
      "alpha: 11.200000000000001 | train error: 30.058768 test error: 40.431471\n",
      "alpha: 11.4 | train error: 30.058842 test error: 40.431844\n",
      "alpha: 11.600000000000001 | train error: 30.058916 test error: 40.432212\n",
      "alpha: 11.8 | train error: 30.058989 test error: 40.432577\n",
      "alpha: 12.0 | train error: 30.059062 test error: 40.432939\n",
      "alpha: 12.200000000000001 | train error: 30.059135 test error: 40.433297\n",
      "alpha: 12.4 | train error: 30.059207 test error: 40.433652\n",
      "alpha: 12.600000000000001 | train error: 30.059278 test error: 40.434004\n",
      "alpha: 12.8 | train error: 30.059349 test error: 40.434352\n",
      "alpha: 13.0 | train error: 30.05942 test error: 40.434698\n",
      "alpha: 13.200000000000001 | train error: 30.05949 test error: 40.43504\n",
      "alpha: 13.4 | train error: 30.05956 test error: 40.43538\n",
      "alpha: 13.600000000000001 | train error: 30.05963 test error: 40.435717\n",
      "alpha: 13.8 | train error: 30.059699 test error: 40.436051\n",
      "alpha: 14.0 | train error: 30.059767 test error: 40.436382\n",
      "alpha: 14.200000000000001 | train error: 30.059836 test error: 40.436711\n",
      "alpha: 14.4 | train error: 30.059903 test error: 40.437037\n",
      "alpha: 14.600000000000001 | train error: 30.059971 test error: 40.43736\n",
      "alpha: 14.8 | train error: 30.060038 test error: 40.437681\n",
      "alpha: 15.0 | train error: 30.060105 test error: 40.437999\n",
      "alpha: 15.200000000000001 | train error: 30.060171 test error: 40.438315\n",
      "alpha: 15.4 | train error: 30.060237 test error: 40.438629\n",
      "alpha: 15.600000000000001 | train error: 30.060303 test error: 40.43894\n",
      "alpha: 15.8 | train error: 30.060368 test error: 40.439249\n",
      "alpha: 16.0 | train error: 30.060433 test error: 40.439556\n",
      "alpha: 16.2 | train error: 30.060497 test error: 40.43986\n",
      "alpha: 16.400000000000002 | train error: 30.060561 test error: 40.440163\n",
      "alpha: 16.6 | train error: 30.060625 test error: 40.440463\n",
      "alpha: 16.8 | train error: 30.060688 test error: 40.440761\n",
      "alpha: 17.0 | train error: 30.060752 test error: 40.441057\n",
      "alpha: 17.2 | train error: 30.060814 test error: 40.441351\n",
      "alpha: 17.400000000000002 | train error: 30.060877 test error: 40.441644\n",
      "alpha: 17.6 | train error: 30.060939 test error: 40.441934\n",
      "alpha: 17.8 | train error: 30.061 test error: 40.442222\n",
      "alpha: 18.0 | train error: 30.061062 test error: 40.442509\n",
      "alpha: 18.2 | train error: 30.061123 test error: 40.442793\n",
      "alpha: 18.400000000000002 | train error: 30.061184 test error: 40.443076\n",
      "alpha: 18.6 | train error: 30.061244 test error: 40.443357\n",
      "alpha: 18.8 | train error: 30.061304 test error: 40.443636\n",
      "alpha: 19.0 | train error: 30.061364 test error: 40.443913\n",
      "alpha: 19.200000000000003 | train error: 30.061424 test error: 40.444189\n",
      "alpha: 19.400000000000002 | train error: 30.061483 test error: 40.444463\n",
      "alpha: 19.6 | train error: 30.061542 test error: 40.444735\n",
      "alpha: 19.8 | train error: 30.0616 test error: 40.445006\n"
     ]
    }
   ],
   "source": [
    "# Set alpha as a series of multiples of 0.2.\n",
    "alphas = [i*0.2 for i in range(0,100)]\n",
    "for alpha in alphas:\n",
    "    # Instantiate the ridge regression model and fit the data.\n",
    "    ridge = Ridge(alpha=alpha, fit_intercept=True, random_state=46)\n",
    "    ridge.fit(x_train, y_train)\n",
    "    # Calculate the train and test errors.\n",
    "    new_train_error = np.sqrt(mean_squared_error(y_train, ridge.predict(x_train)))\n",
    "    new_test_error = np.sqrt(mean_squared_error(y_test, ridge.predict(x_test)))\n",
    "    # Print errors as report.\n",
    "    print('alpha: {} | train RMSE: {} test RMSE: {}'.format(alpha,round(new_train_error,6),round(new_test_error,6)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 3: Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set alpha as a series of multiples of 0.2.\n",
    "alphas = [i*0.2 for i in range(0,100)]\n",
    "for alpha in alphas:\n",
    "    # Instantiate the lasso regression model and fit the data.\n",
    "    lasso = Lasso(alpha=alpha, fit_intercept=True, random_state=46)\n",
    "    lasso.fit(x_train, y_train)\n",
    "    # Calculate the train and test errors.\n",
    "    new_train_error = np.sqrt(mean_squared_error(y_train, lasso.predict(x_train)))\n",
    "    new_test_error = np.sqrt(mean_squared_error(y_test, lasso.predict(x_test)))\n",
    "    # Print errors as report.\n",
    "    print('alpha: {} | train RMSE: {} test RMSE: {}'.format(alpha,round(new_train_error,6),round(new_test_error,6)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.07146315,  0.06007947, -0.        ,  0.01599065,  0.13351931,\n",
       "        0.        ,  0.        , -0.        ,  0.        ,  0.03991606,\n",
       "        0.        ,  0.        ,  0.        ,  0.01193697,  0.        ,\n",
       "        0.        ,  0.        , -0.        , -0.03770052,  0.        ,\n",
       "        0.        ,  0.        ,  0.00148093,  0.        ,  0.        ,\n",
       "        0.        ,  0.        , -0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        , -0.        ,\n",
       "        0.        ,  0.        , -0.        ,  0.        , -0.        ,\n",
       "        0.        ,  0.        , -0.        ,  0.        , -0.        ,\n",
       "       -0.01838712,  0.16376379, -0.        , -0.04129069,  0.04999613,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "       -0.11376435,  0.00016691,  0.        , -0.        , -0.        ,\n",
       "       -0.        , -0.        , -0.        ,  0.        , -0.        ,\n",
       "       -0.        , -0.        , -0.        , -0.        , -0.        ,\n",
       "       -0.        ,  0.        , -0.        ,  0.        , -0.        ,\n",
       "       -0.        , -0.        ,  0.        , -0.        ,  0.        ,\n",
       "       -0.        , -0.        ,  0.        , -0.        ,  0.        ,\n",
       "       -0.        ,  0.        ,  0.        , -0.        , -0.        ,\n",
       "        0.        , -0.        ,  0.        , -0.        , -0.        ,\n",
       "       -0.        ,  0.        ,  0.        , -0.        ,  0.        ,\n",
       "       -0.        , -0.        , -0.        , -0.        , -0.        ,\n",
       "       -0.        , -0.        , -0.        , -0.        , -0.        ,\n",
       "       -0.        , -0.        ,  0.        , -0.        , -0.        ,\n",
       "        0.        , -0.        , -0.        ,  0.        , -0.        ,\n",
       "       -0.        , -0.        , -0.        , -0.        , -0.        ,\n",
       "       -0.        , -0.        ,  0.        , -0.        , -0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        , -0.        ,\n",
       "        0.        ,  0.        , -0.        ,  0.        , -0.        ,\n",
       "       -0.        , -0.        , -0.        , -0.        , -0.        ,\n",
       "        0.        , -0.        , -0.        ,  0.        , -0.        ,\n",
       "       -0.        , -0.        ,  0.        , -0.        , -0.        ,\n",
       "       -0.        , -0.        ,  0.        , -0.        , -0.        ,\n",
       "       -0.        , -0.        , -0.        , -0.        , -0.        ,\n",
       "        0.        , -0.        , -0.        , -0.        , -0.        ,\n",
       "       -0.        , -0.        , -0.        , -0.        ,  0.        ,\n",
       "       -0.        ,  0.        , -0.        ,  0.        , -0.        ,\n",
       "       -0.        , -0.        , -0.        , -0.        , -0.        ,\n",
       "       -0.        ,  0.        ,  0.        , -0.        ,  0.        ,\n",
       "       -0.        , -0.        , -0.        ,  0.        , -0.        ,\n",
       "       -0.        ,  0.        , -0.        , -0.        ,  0.        ,\n",
       "       -0.        ,  0.        ,  0.        , -0.        ,  0.        ,\n",
       "       -0.        , -0.        , -0.        ,  0.        , -0.        ,\n",
       "        0.        , -0.        ,  0.        , -0.        , -0.        ,\n",
       "        0.        , -0.        , -0.        , -0.        , -0.        ,\n",
       "        0.        , -0.        , -0.        , -0.        ,  0.        ,\n",
       "       -0.        ,  0.        ,  0.        , -0.        , -0.        ,\n",
       "       -0.        , -0.        , -0.        , -0.        , -0.        ,\n",
       "        0.        , -0.        , -0.        , -0.        , -0.        ,\n",
       "       -0.        , -0.        ,  0.        , -0.        , -0.        ,\n",
       "        0.        ,  0.        , -0.        , -0.        , -0.        ,\n",
       "       -0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        , -0.        ,  0.        ,  0.        , -0.        ,\n",
       "       -0.        , -0.        , -0.        ,  0.        , -0.        ,\n",
       "       -0.        , -0.        , -0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coeff=lasso.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top features in Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most important features:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(51, 0.16376378778312045),\n",
       " (4, 0.13351930903691636),\n",
       " (0, 0.07146314980038826),\n",
       " (1, 0.060079469033783355),\n",
       " (54, 0.049996134789007544),\n",
       " (9, 0.039916055366845796),\n",
       " (3, 0.015990649934812477),\n",
       " (13, 0.011936969349406416),\n",
       " (22, 0.0014809309542255734),\n",
       " (61, 0.00016690650053778437)]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_features=list(zip(x_train.columns,coeff))\n",
    "lasso_features\n",
    "\n",
    "def Sort(x):\n",
    "    return(sorted(x, key=lambda x: float(x[1]), reverse=True))\n",
    "lasso_important=Sort(lasso_features)\n",
    "\n",
    "print(\"Most important features:\")\n",
    "lasso_important[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2 Spectral Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method 1. Using Networkx and Scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1]]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clustering with Networkx\n",
    "\n",
    "# Read the data. Data is in graph format.\n",
    "G=nx.read_gml(\"/Users/advaitiyer/Desktop/Syracuse University/Academics/3rd Semester/Analytical Data Mining CIS 787/Homeworks/HW4/karate.gml.txt\",label='id')\n",
    "\n",
    "# for line in nx.generate_adjlist(G):\n",
    "#     print(line)\n",
    "\n",
    "# Create adjacency matrix from the graph data.\n",
    "A=nx.adjacency_matrix(G)\n",
    "# print(A.todense())\n",
    "\n",
    "# Conduct Spectral clustering with Scikit-learn's Spectral Clustering method.\n",
    "spectral_clustering=cluster.SpectralClustering(n_clusters=2,affinity=\"precomputed\", n_init=200)\n",
    "spectral_clustering.fit(A)\n",
    "results=[]\n",
    "results.append(list(spectral_clustering.labels_))\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method 2. Using Linear algebra, and k-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "degree matrix:\n",
      "[[16  0  0 ...  0  0  0]\n",
      " [ 0  9  0 ...  0  0  0]\n",
      " [ 0  0 10 ...  0  0  0]\n",
      " ...\n",
      " [ 0  0  0 ...  6  0  0]\n",
      " [ 0  0  0 ...  0 12  0]\n",
      " [ 0  0  0 ...  0  0 17]]\n",
      "Laplacian matrix:\n",
      "[[16 -1 -1 ... -1  0  0]\n",
      " [-1  9 -1 ...  0  0  0]\n",
      " [-1 -1 10 ...  0 -1  0]\n",
      " ...\n",
      " [-1  0  0 ...  6 -1 -1]\n",
      " [ 0  0 -1 ... -1 12 -1]\n",
      " [ 0  0  0 ... -1 -1 17]]\n"
     ]
    }
   ],
   "source": [
    "# Create degree matrix from the adjacency matrix.\n",
    "D=np.diag(np.sum(np.array(A.todense()),axis=1))\n",
    "print(\"degree matrix:\")\n",
    "print(D)\n",
    "\n",
    "# Create Laplacian matrix.\n",
    "L=D-A\n",
    "print(\"Laplacian matrix:\")\n",
    "print(L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eigenvalues:\n",
      "[1.81366960e+01 1.70551712e+01 1.33061223e+01 1.09210675e+01\n",
      " 9.77724095e+00 6.99619703e+00 6.51554463e+00 6.33159222e+00\n",
      " 5.61803399e+00 5.37859508e+00 4.58079267e+00 4.48000767e+00\n",
      " 4.27587682e+00 3.47218740e+00 3.38196601e+00 3.37615409e+00\n",
      " 3.24206748e+00 3.01396297e+00 2.74915718e+00 2.48709173e+00\n",
      " 2.00000000e+00 2.00000000e+00 2.00000000e+00 2.00000000e+00\n",
      " 2.00000000e+00 1.95505045e+00 1.82605521e+00 1.76189862e+00\n",
      " 1.59928308e+00 1.25940411e+00 1.12501072e+00 9.09247664e-01\n",
      " 4.68525227e-01 6.84538602e-15]\n",
      "Eigenvectors:\n",
      "[[ 0.19374903 -0.94093217 -0.09478253 ... -0.06940423 -0.11213743\n",
      "  -0.17149859]\n",
      " [ 0.00522422  0.06586476  0.09918451 ... -0.09514749 -0.04128789\n",
      "  -0.17149859]\n",
      " [ 0.02918609  0.11506912 -0.31479791 ... -0.04270411  0.02321896\n",
      "  -0.17149859]\n",
      " ...\n",
      " [-0.0855124   0.07685092 -0.12302713 ...  0.02830225  0.09875343\n",
      "  -0.17149859]\n",
      " [-0.05907528 -0.07434337  0.88955887 ...  0.03779294  0.13034546\n",
      "  -0.17149859]\n",
      " [ 0.94347941  0.20184142  0.0374803  ...  0.02839394  0.11890326\n",
      "  -0.17149859]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "eigenvalues,eigenvectors=np.linalg.eig(L)\n",
    "\n",
    "# Compute eigenvalues. Sort them in descending order.\n",
    "print(\"Eigenvalues:\")\n",
    "ids=eigenvalues.argsort()[::-1]\n",
    "eigenvalues=eigenvalues[ids]\n",
    "print(eigenvalues)\n",
    "plt.plot(eigenvalues)\n",
    "\n",
    "\n",
    "# Compute eigenvectors. Sort them through the ids of eigenvalue array.\n",
    "print(\"Eigenvectors:\")\n",
    "eigenvectors=eigenvectors[:,ids]\n",
    "print(eigenvectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1,\n",
       "       0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0], dtype=int32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# K-means:\n",
    "\n",
    "# Run k-means clustering algorithm using 2 clusters.\n",
    "kmeans_clustering=cluster.KMeans(n_clusters=2)\n",
    "kmeans_clustering.fit(np.transpose(eigenvectors))\n",
    "clusters=kmeans_clustering.labels_\n",
    "# Print the clusters.\n",
    "clusters"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
